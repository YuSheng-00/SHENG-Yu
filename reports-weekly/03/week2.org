# -*- coding: utf-8; mode: org -*-

* Research Activities
- papers(论文):
  1.System 1 + System 2 = Better World: Neural-Symbolic Chain of Logic Reasoning
利用神经符号方法，将基于神经网络，建立可以表达命题逻辑形式的可微分框架，增强表示学习过程，提高了在大规模常识知识图谱链路预测问题上的性能。

  2.NEURAL LOGIC ANALOGY LEARNING
模型的主要结构和上一篇（1）类似，只是应用的任务不同
主要方法：NS方法，将每个字符类比问题的表达成命题逻辑表达式的形式，然后将表达式建模成（1）中逻辑操作符作为网络，embedding作为网络输入的推理模型框架

- ideas(新的想法):
尝试在实验中加入对比损失

思考：如何找到更合适的建模方法，可以更好利用一阶逻辑的特性（描述对象性质）

* Project Activities
- code learning(代码学习):

  变学习率的代码设置
  结果可视化 visdom 模块
  GAT网络的batch实现

- experiments(实验设计&结果):

  实验：
  1.baseline : 稳定值50%左右，最高值53%左右，但无法实现论文上报告的59%的准确率
  2.GCN+attention: 稳定值54%-55% ,最高值56%，与baseline相比有所提升，但并未超过论文数字，且提升效果并不算太显著
  3.GAT：稳定值 50%左右，且出现了train set上准确率下降的情况，无法确定是学习率引起的，还是模型结构引起的，需要重新实验一下

- 探索chatGPT的自然语言推理能力：
  在3.5的接口上进行实验，准确率为48.03%，低于监督方法，说明暂时目前GPT的推理能力仍有所欠缺
* Teams and Services
  1. 组会
     李：知识图谱的零次学习 + 层次树学习  comGC:学习边的关系，考虑是否可以借鉴到自己做的方法里
     周：单玩家文本游戏  语言模型+ 强化学习的结合   语言模型用于生成动作空间  RL用于探索
     耿：多模态信息抽取  把自己的special words 加入大模型的vocabulary里，但是需要预训练
     
* Lessons Learned
- 经典知识学习

* Problems Encountered
- prob 1
问题：
baseline 实验无法达到论文里的准确率
解决方案:
尝试一下RoBERTa模型 ，查看实验结果

是否已解决：否 （实验还没做）
- prob 2
问题：
数据集上实验准确率提升不明显
解决方案：
考虑其他结构或者正则项，进一步显式的利用一阶逻辑的结构优势和逻辑信息
是否已解决：
否，需要进一步学习优化知识并探索

* Plan:
1.RoBERTa实验，查看准确率   重复GAT实验，这次不改变学习率选择策略，仅比较两种模型结构的效果优劣
2.提高论文阅读量，围绕“大模型如何进一步提升逻辑推理能力”展开，做好记录，准备开题
3.学习经典书籍和算法
